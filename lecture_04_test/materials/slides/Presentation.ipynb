{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Testing \n",
    "\n",
    "- When?\n",
    "- Why?\n",
    "- How?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## When? \n",
    "\n",
    "Always,\n",
    "\n",
    "but:\n",
    "- This code will be thrown away soon \n",
    "  - Challenge solving on www.haccerrank.com,  www.leetcode.com, etc\n",
    "  - Code that runs once\n",
    "  - Code that does not require quality: prototypes, POC(proof of concept) \n",
    "- Technical code that has a single purpose and run automatically\n",
    "  - Automation scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why?\n",
    "\n",
    "- To be sure that your code do what you ask it to do (finding bug is a side effect)\n",
    "- Get fast and precise feedback \n",
    "- Improve speed of introducing changes\n",
    "- Reduce time spent in dubugging\n",
    "- Remove fear of changes\n",
    "- Force you to have an architecture (boundaries management)\n",
    "- You think what you write \n",
    "- Tests are code documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How?\n",
    "- Test are first class sitezens\n",
    "- Rules for writting code and tests are different\n",
    "- Write code with tests in mind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Test types\n",
    "\n",
    "- Functional\n",
    "    - Unittest (we are talking about them today)\n",
    "    - Not unittests: component, servce, integration, end-to-end\n",
    "- Non functional:\n",
    "  - performance\n",
    "  - stress\n",
    "  - security\n",
    "  \n",
    "Don't try to write test that fits into multiple categories at once. They will be bad at all of them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is unit stands for?\n",
    "\n",
    "- function\n",
    "- class\n",
    "- method\n",
    "- module\n",
    "- package\n",
    "- service\n",
    "\n",
    "Unit is a chunk of code that can be tested.\n",
    "No global definition, need to define it for each project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A test is not a unit test if:\n",
    "- It talks to the database\n",
    "- It communicates across the network\n",
    "- It touches the file system\n",
    "- It can't run at the same time as any of your other unit tests\n",
    "- You have to do special things to your environment (such as editing config files) to run it. \n",
    "\n",
    "[Michael Feathers. A Set of Unit Testing Rules](https://www.artima.com/weblogs/viewpost.jsp?thread=126923)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Test pyramid\n",
    "\n",
    "Many easy and fast test, less slow and complicated\n",
    "\n",
    "![https://martinfowler.com/articles/practical-test-pyramid.html](img/test_pyramid.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: We have a sysem with modules\n",
    "\n",
    "![arch_tree](img/arch_tree.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Module 6 has an issue\n",
    "\n",
    "Issue in a module fails each dependent module.\n",
    "You cannot build a good system on bad blocks.\n",
    "\n",
    "- Module 6 is on level 1 and has 0 dependencies\n",
    "- Module 3 is on level 2 and has 2 dependencies\n",
    "- Module 1 is on level 3 and has 6 dependencies\n",
    "\n",
    "On weach level it is better to catch error in module 6?\n",
    "\n",
    "![arch_tree](img/arch_tree_red.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example\n",
    "\n",
    "We have a feature that accepts an image, detect its attributes and proveides an info about image. To test each case we need to provide an imege.\n",
    "\n",
    "We wrote a banch of functions: `get_color` and `get_shape` are on the first level, `get_image_info` is on the second.\n",
    "\n",
    "```python\n",
    "def get_color(img) -> str:\n",
    "    \"\"\"Return one of colors from Red, Green, Blue.\"\"\"\n",
    "\n",
    "\n",
    "def get_shape(img) -> bool:\n",
    "    \"\"\"Return one of shapes: Box, Circle.\"\"\"\n",
    "\n",
    "def get_image_info(img):\n",
    "    shape = get_shape(img)\n",
    "    color = get_color(img)\n",
    "    return f\"This is {color} {shape}.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Test from the top (reversed test pyramid)\n",
    "\n",
    "We want to test all positive scenarious so we provide an image for each possible case.\n",
    "\n",
    "- `get_image_info` gives us 6 positive tests and 6 images (3 colors x 2 shapes )\n",
    "    - test_red_box\n",
    "    - test_red_cycle\n",
    "    - test_green_box\n",
    "    - test_green_cycle\n",
    "    - test_blue_box\n",
    "    - test_blue_cycle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Test from bottom (test pyramid)\n",
    "\n",
    "- `get_color` gives us 3 test and 3 images,\n",
    "   we test that color was detected\n",
    "    - test_red\n",
    "    - test_blue\n",
    "    - test_green\n",
    "- `get_shape` us 2 test and 2 images,\n",
    "  we test that shape was detected\n",
    "    - test_box\n",
    "    - test_cycle\n",
    "- `get_image_info` gives us 1 test 1 image, \n",
    "   we test what `get_color` and `get_shape` and return value is properly formed. Actually you need 0 images, because you mock level 1 calls\n",
    "    - test_image_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Add a new color\n",
    "\n",
    "```python\n",
    "def get_color(img) -> str:\n",
    "    \"\"\"Return one of colors from Red, Green, Blue, Violent.\"\"\"\n",
    "```\n",
    "\n",
    "- Test from the top\n",
    "    - 4 * 2 -> 8 test \n",
    "- Test from bottom\n",
    "    - 4 + 2 + 1 -> 7 tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Rename color \n",
    "\n",
    "```python\n",
    "def get_color(img) -> str:\n",
    "    \"\"\"Return one of colors from Red, Green, Blue, Violet.\"\"\"\n",
    "```\n",
    "\n",
    "- Test from the top\n",
    "    - 2 test changes \n",
    "- Test from bottom\n",
    "    - 1 test changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "You can build a good program on top of tested blocks. \n",
    "\n",
    "Python itself is well tested.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Test requirements\n",
    "\n",
    "- independent, one test does not affect others\n",
    "- informative, you can understand a case coverd by the test  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Testing scenarious\n",
    "\n",
    "- positive, sunny, critical path (you test how feature work)\n",
    "- negative (you test how you code handle bad things)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tests are code but require different approach\n",
    "\n",
    "- Test name can be long and descriptive, you never call it from code\n",
    "- Input and expected values for each test are different thing even if they look the same, don't extract them to common variables \n",
    "- Make linter less trict for tests\n",
    "- Treat them as code, review and maintain them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What should be tested\n",
    "\n",
    "```python\n",
    "def is_not_negative(a: int) -> bool:\n",
    "    return a > 0\n",
    "```\n",
    "\n",
    "Input is from `-inf` to `+inf` so we cannot test everything,\n",
    "lets split it to groups and check one candidate per group.\n",
    "\n",
    "<details>\n",
    "    <summary><b>Spoiler click me to see the groups</b></summary>\n",
    "\n",
    "- -3 negative values `(-inf,  -1)`      \n",
    "- 0 for zero, because it is part of our fucntion\n",
    "- -1 for left border of special value\n",
    "- 1 for right border of special value\n",
    "- 3 for positive values `(1, +inf)`\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Things to think about when splitting arguments to groups\n",
    "\n",
    "\n",
    "## Positive\n",
    "- comon value\n",
    "- min, max\n",
    "- border, border + 1, border - 1\n",
    "- special 0, Null, special for your unit\n",
    "    \n",
    "## Negative\n",
    "- exception raised with proper message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Name your tests well\n",
    "\n",
    "### bad\n",
    "```\n",
    "test_1\n",
    "test_2\n",
    "test_positive\n",
    "test_function\n",
    "test_is_leap_year\n",
    "```\n",
    "\n",
    "### Good test names\n",
    "```\n",
    "test_years_not_divisible_by_4_are_not_leap_years\n",
    "test_years_divisible_by_4_but_not_by_100_are_leap_years\n",
    "test_years_divisible_by_100_but_not_by_400_are_not_leap_years\n",
    "test_years_divisible_by_400_are_leap_years\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Keep it simple\n",
    "It should be easy to understand what is goind in and out.\n",
    "\n",
    "### bad\n",
    "```python\n",
    "assert find_maximal_subarray_sum(\n",
    "    [1, 3, -1, -3, 5, 3, 6, 7,  5, 3, 6, 7, -7 -2, 3, -15, 77, 11, -3, -5, 99], 10\n",
    ") == 179\n",
    "```\n",
    "\n",
    "```python\n",
    "file_maker(\n",
    "        [i for i in range(2)] + [-10] + [i + 10 for i in range(2)],\n",
    "        \"data_test_task03_min-10_max19.txt\",\n",
    "        )\n",
    "assert find_maximum_and_minimum(\"data_test_task03_min1_max1.txt\"), (1, 1)\n",
    "```\n",
    "\n",
    "\n",
    "### good\n",
    "```python\n",
    "assert find_maximal_subarray_sum([1, 2, 2], 10) == 6\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Guess a variable by name by its value\n",
    "\n",
    "- 42 [good example](https://en.wikipedia.org/wiki/2020)\n",
    "- \"ostolop\" [good example](https://en.wikipedia.org/wiki/List_of_accounting_roles#Junior_accountant)\n",
    "- \"АВС\" [good example](https://en.wikipedia.org/wiki/Lorem_ipsum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How to structure\n",
    "\n",
    "May names all about the same\n",
    "\n",
    "- Arrange, Act, Assert (AAA)\n",
    "- Given, When, Then\n",
    "\n",
    "Always in that order, at most one section of each type.\n",
    "\n",
    "### good\n",
    "```python\n",
    "def test_constuctor_call_produces_object():\n",
    "    args = [1, 2, 3]  # Arrange | Given\n",
    "    foo = Foo(args)  # Act | When\n",
    "    assert foo.sum = 6  # Assert | Then\n",
    "```\n",
    "\n",
    "### bad\n",
    "```python\n",
    "def test_constuctor_call_produces_object():\n",
    "    args = [1, 2, 3]  # Arrange | Given\n",
    "    args2 = [1, 2]\n",
    "    foo = Foo(args)  # Act | When\n",
    "    foo2 = Foo(args2)  # Act | When\n",
    "    assert foo.sum = 6  # Assert | Then\n",
    "    assert foo.sum = 6  # Assert | Then\n",
    "```\n",
    "\n",
    "- Test is more complex, it's easier to have a mistake (Do you see it?)\n",
    "- One test depends on other (if one of them failed other is not checked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## pytest: helps you write better programs\n",
    "\n",
    "The pytest framework makes it easy to write small tests, yet scales to support complex functional testing for applications and libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Test runner\n",
    "\n",
    "**pytest** will run all files of the form `test_*.py` or `*_test.py` in the current directory and its subdirectories. \n",
    "\n",
    "More generally, it follows standard test discovery rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## pytest fixtures: explicit, modular, scalable\n",
    "fixture - prepared data for test\n",
    "\n",
    "- function\n",
    "- scope\n",
    "- nested\n",
    "- builtin fixtures\n",
    "- tear down\n",
    "- autouse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fixture example\n",
    "\n",
    "- Write a function\n",
    "- Decorate with @pytest.fixture()\n",
    "- Pass as argument to tests\n",
    "- **pytest** will do it's magic\n",
    "\n",
    "\n",
    "```python\n",
    "import pytest\n",
    "\n",
    "\n",
    "@pytest.fixture()\n",
    "def smtp_connection():\n",
    "    import smtplib\n",
    "\n",
    "    return smtplib.SMTP(\"smtp.gmail.com\", 587, timeout=5)\n",
    "\n",
    "\n",
    "def test_ehlo(smtp_connection):\n",
    "    response, msg = smtp_connection.ehlo()\n",
    "    assert response == 250\n",
    "    assert 0  # for demo purposes\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What pytest do after you run it\n",
    "\n",
    "- Collect fixtures\n",
    "- Collect tests\n",
    "- Run tests\n",
    "- Show reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fixture scopes\n",
    "- function (default, recomended)\n",
    "- class\n",
    "- module\n",
    "- package\n",
    "- session\n",
    "\n",
    "Use `function` everythere and other to umprove performance.\n",
    "\n",
    "```python\n",
    "# content of conftest.py\n",
    "import pytest\n",
    "import smtplib\n",
    "\n",
    "\n",
    "@pytest.fixture(scope=\"module\")\n",
    "def smtp_connection():\n",
    "    return smtplib.SMTP(\"smtp.gmail.com\", 587, timeout=5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Nested fixtures (fixture in fixture)\n",
    "\n",
    "```python\n",
    "import pytest\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def john():\n",
    "    return \"John\"\n",
    "\n",
    "@pytest.fixture\n",
    "def user_john(name):\n",
    "    return User(name)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Built-in fixtures\n",
    "\n",
    "- caplog Control logging and access log entries.\n",
    "- capsys Capture, as text, output to sys.stdout and sys.stderr.\n",
    "- monkeypatch Temporarily modify classes, functions, dictionaries, os.environ, and other objects.\n",
    "- pytestconfig Access to configuration values, pluginmanager and plugin hooks.\n",
    "- request Provide information on the executing test function.\n",
    "- testdir Provide a temporary test directory to aid in running, and testing, pytest plugins.\n",
    "- tmp_path Provide a pathlib.Path object to a temporary directory which is unique to each test function.\n",
    "- [and others](https://docs.pytest.org/en/stable/fixture.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## monkeypatch\n",
    "\n",
    "Modify your environment to before the test, get it cleaned after automatically.\n",
    "\n",
    "- monkeypatch.setattr(obj, name, value, raising=True)\n",
    "- monkeypatch.delattr(obj, name, raising=True)\n",
    "- monkeypatch.setitem(mapping, name, value)\n",
    "- monkeypatch.delitem(obj, name, raising=True)\n",
    "- monkeypatch.setenv(name, value, prepend=False)\n",
    "- monkeypatch.delenv(name, raising=True)\n",
    "- monkeypatch.syspath_prepend(path)\n",
    "- monkeypatch.chdir(path)\n",
    "\n",
    "```python\n",
    "import sys\n",
    "\n",
    "\n",
    "def foo():\n",
    "    return 1\n",
    "\n",
    "\n",
    "def boo(x):\n",
    "    return x + foo()\n",
    "\n",
    "\n",
    "def test_boo_with_monkeypatch(monkeypatch):\n",
    "    this_module = sys.modules[__name__]\n",
    "    monkeypatch.setattr(this_module, \"foo\", lambda: 2)\n",
    "    assert boo(1) == 3\n",
    "\n",
    "\n",
    "def test_boo(monkeypatch):\n",
    "    assert boo(1) == 2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fixture instead of setUp and tearDown\n",
    "\n",
    "```python\n",
    "import pytest\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def connection():\n",
    "    con = get_connection()\n",
    "    yield con\n",
    "    con.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Use fixture without adding argument\n",
    "\n",
    "```python\n",
    "# content of test_setenv.py\n",
    "import os\n",
    "import pytest\n",
    "\n",
    "\n",
    "@pytest.mark.usefixtures(\"cleandir\")\n",
    "class TestDirectoryInit:\n",
    "    def test_cwd_starts_empty(self):\n",
    "        assert os.listdir(os.getcwd()) == []\n",
    "        with open(\"myfile\", \"w\") as f:\n",
    "            f.write(\"hello\")\n",
    "\n",
    "    def test_cwd_again_starts_empty(self):\n",
    "        assert os.listdir(os.getcwd()) == []\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Run before any test\n",
    "\n",
    "```python\n",
    "@pytest.fixture(autouse=True)\n",
    "def a1():\n",
    "    order.append(\"a1\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Test generation\n",
    "\n",
    "```python\n",
    "import pytest\n",
    "\n",
    "\n",
    "@pytest.mark.parametrize(\"color\", [\"red\", \"green\"])\n",
    "@pytest.mark.parametrize(\"shape\", [\"box\", \"circle\"])\n",
    "def test_shape(shape, color):\n",
    "    assert True\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "test/test_example.py::test_shape[box-red] PASSED                                                                         \n",
    "test/test_example.py::test_shape[box-green] PASSED                                                                       \n",
    "test/test_example.py::test_shape[circle-red] PASSED                                                               \n",
    "test/test_example.py::test_shape[circle-green] PASSED   \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### bad\n",
    "\n",
    "All in one, you don't help reader to understand cases behind this inputs. \n",
    "\n",
    "```python\n",
    "@pytest.mark.parametrize(\n",
    "    [\"value\", \"expected_result\"],\n",
    "    [\n",
    "        ([0, 1, 1, 2], True),\n",
    "        ([], False),\n",
    "        ([0], False),\n",
    "        ([0, 1, 1, 3], False),\n",
    "        ([1, 1, 2], False),\n",
    "    ],\n",
    ")\n",
    "def test_check_fibonacci(value: Sequence[int], expected_result: bool):\n",
    "    actual_result = check_fibonacci(value)\n",
    "\n",
    "    assert actual_result == expected_result\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### good\n",
    "```python\n",
    "\n",
    "@pytest.mark.parametrize(\n",
    "    \"value\",\n",
    "    [\n",
    "        [0, 1, 1, 2]\n",
    "\n",
    "    ],\n",
    ")\n",
    "def test_sequence_is_fibonacci(value: Sequence[int]):\n",
    "    assert check_fibonacci(value) is True\n",
    "\n",
    "\n",
    "@pytest.mark.parametrize(\n",
    "    \"value\",\n",
    "    [\n",
    "        [],\n",
    "        [0],\n",
    "        [0, 1, 1, 3],\n",
    "        [1, 1, 2],\n",
    "    ],\n",
    ")\n",
    "def test_sequence_is_not_fibonacci(value: Sequence[int]):\n",
    "    assert check_fibonacci(value) is False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## conftest.py\n",
    "\n",
    "- stores fixtures that will be available to all files in module\n",
    "- can be present in each test subfolder\n",
    "- if multiple files are present in hierarchy, all of the executed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Unittest vs pytest\n",
    "- pytest asserts are more informative\n",
    "- pytest fixtures are more flexible that setUp and tearDown\n",
    "- pytest does not reqire to do test classes\n",
    "- pytest has plugins\n",
    "- pytest is more widly used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Typical errors\n",
    "- many test in a single test\n",
    "- test coupling\n",
    "- test wrong exception\n",
    "- assert nothing\n",
    "- not detailed assert\n",
    "- assert floating point \n",
    "- test your mock\n",
    "- test unreliable sources (fail with no reason)\n",
    "- cleanup in test body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Many test in a single test\n",
    "\n",
    "- Error can be hidden by other errors\n",
    "- More chance to make an error in tests\n",
    "\n",
    "```python\n",
    "def test_user_...():\n",
    "    admin = User(...)\n",
    "    assert admin.get....\n",
    "    \n",
    "    user = User(...)\n",
    "    assert user.get....\n",
    "    \n",
    "    guest = User(...)\n",
    "    assert guest.get....\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Test coupling\n",
    "```python\n",
    "state = True\n",
    "\n",
    "\n",
    "def test_state_set_state():\n",
    "    global state\n",
    "    state = False\n",
    "    assert state is False\n",
    "\n",
    "\n",
    "def test_get_state():\n",
    "    assert state is False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Test wrong exception\n",
    "```python\n",
    "def foo(text: int):\n",
    "    if text <= 0:\n",
    "        raise ValueError(\"Positive number required\")\n",
    "```\n",
    "\n",
    "### bad\n",
    "```python\n",
    "def test_negative_integer_raises_and_error():\n",
    "    with pytest.raises(ValueError):\n",
    "        foo(\"-1\")\n",
    "```\n",
    "\n",
    "### good\n",
    "```python\n",
    "def test_negative_integer_raises_and_error():\n",
    "    with pytest.raises(ValueError, match=\"Positive number required\"):\n",
    "        foo(\"-1\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Assert nothing\n",
    "```python\n",
    "def test_fibonacci():\n",
    "    check_fibonacci([3, 1])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Not detailed assert\n",
    "```python\n",
    "def test_minor_and_major():\n",
    "    assert major_and_minor_elem([1, 2, 3])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Assert floating point \n",
    "\n",
    "### bad\n",
    "```python\n",
    "def test_float_bad():\n",
    "    assert 0.1 + 0.2 == 0.3\n",
    "```\n",
    "   \n",
    "```\n",
    "    def test_float_bad():\n",
    ">       assert 0.1 + 0.2 == 0.3\n",
    "E       assert 0.30000000000000004 == 0.3\n",
    "E         +0.30000000000000004\n",
    "E         -0.3\n",
    "```\n",
    "\n",
    "### good\n",
    " \n",
    "```python\n",
    "def test_float_good():\n",
    "    assert 0.1 + 0.2 == pytest.approx(0.3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Test your mock\n",
    "```python\n",
    "def connection_mock(url):\n",
    "    return {\"message\": \"OK\"}\n",
    "\n",
    "\n",
    "def test_connection():\n",
    "    assert connection_mock(\"http://localhost\") == {\"message\": \"OK\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Test unreliable sources\n",
    "\n",
    "If test is passed or failed depends not on you, but on some 3d party.\n",
    "\n",
    "```python\n",
    "def test_connection():\n",
    "    assert connect(\"http://production.com/api/v3/status\") == {\"message\": \"OK\"}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Cleanup in test body\n",
    "\n",
    "If test fails, cleanup is not happen\n",
    "\n",
    "```python\n",
    "def test_file():    \n",
    "    create_txt_file(text, \"test_text.txt\")\n",
    "    assert count_punctuation_chars(\"test_text.txt\") == 6\n",
    "    os.remove(\"test_text.txt\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Test doubles: Mock and Spy \n",
    "\n",
    "Mock and MagicMock objects create all attributes and methods as you access them and store details of how they have been used. You can configure them, to specify return values or limit what attributes are available, and then make assertions about how they have been used:\n",
    "\n",
    "```python\n",
    "from unittest.mock import MagicMock\n",
    "thing = ProductionClass()\n",
    "thing.method = MagicMock(return_value=3)\n",
    "thing.method(3, 4, 5, key='value')\n",
    "\n",
    "thing.method.assert_called_with(3, 4, 5, key='value')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Assert call\n",
    "- assert_called()\n",
    "- assert_called_once()\n",
    "- assert_called_with(*args, **kwargs)\n",
    "- assert_called_once_with(*args, **kwargs)\n",
    "- assert_any_call(*args, **kwargs)\n",
    "- assert_has_calls(calls, any_order=False)\n",
    "- assert_not_called()\n",
    "\n",
    "```python\n",
    "mock = Mock()\n",
    "mock.method()\n",
    "\n",
    "mock.method.assert_called()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## doctest\n",
    "\n",
    "```python\n",
    "def is_even(num):\n",
    "    \"\"\"\n",
    "    Return true if number is even\n",
    "\n",
    "    >>> is_even(2)\n",
    "    True\n",
    "\n",
    "    >>> is_even(3)\n",
    "    False\n",
    "    \"\"\"\n",
    "\n",
    "    return num % 2 == 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Сoverage \n",
    "\n",
    "### pytest-cov summary report\n",
    "\n",
    "```\n",
    "Name                        Stmts   Miss  Cover\n",
    "-----------------------------------------------\n",
    "test\\conftest.py               10      0   100%\n",
    "test\\test_declared_env.py      33      0   100%\n",
    "test\\test_example.py            4      1    75%\n",
    "test\\test_variables.py         67      0   100%\n",
    "-----------------------------------------------\n",
    "TOTAL                         114      1    99%\n",
    "```\n",
    "\n",
    "### pytest-cov detailed coverage report\n",
    "![htmlcov/test_test_example_py.html](img/cov.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 100% coverage does not mean your programm works well\n",
    "\n",
    "![htmlcov/test_test_example_py.html](img/cov100.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Coverage metrics\n",
    "\n",
    "| Metric name                     | for developers | for managers |\n",
    "| --- | --- | --- |\n",
    "| Coverage percent                | useless      | useless      |\n",
    "| Coverage changes since previous | important    | usefull      |\n",
    "| Coverage detailed report        | important    | useless      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Debug\n",
    "\n",
    "- debug prints\n",
    "- debug in Pycharm  (https://www.youtube.com/watch?v=sRGpvbhOhQs)\n",
    "- debug with console\n",
    "- remote debug (Pycharm pro, Eclipse)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
